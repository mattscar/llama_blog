---
title: 'Boltzmann Machines and the Nobel Prize'
slug: 'boltmann-machines-nobel-prize'
description: 'Concerning the recent Nobel Prize in Physics'
pubDate: 'October 10, 2024'
---

The 2024 Nobel Prize in Physics has been awarded to John Hopfield and Geoffrey Hinton, and the press release is [here](https://www.nobelprize.org/prizes/physics/2024/press-release). Like many, I was surprised that the award was given to researchers outside the field of physics. I was surprised even more by one statement in the article: 

>The Boltzmann machine can be used to classify images or create new examples of the type of pattern on which it was trained. Hinton has built upon this work, helping initiate the current explosive development of machine learning.

Boltzmann machines are fascinating, but I fail to see how they've influenced the "explosive development of machine learning." From what I've seen, the recent AI explosion is the direct result of the [transformer](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)), better known as the *T* in *ChatGPT*. A transformer is a revolutionary new type of neural network architecture, first described in a 2017 paper from Google Brain called [Attention is All You Need](https://en.wikipedia.org/wiki/Attention_Is_All_You_Need). 

All the large language models (LLMs) in popular use, from Meta's Llama to Google's Gemini to OpenAI's GPT, rely on transformers. Corporations are struggling to improve the speed and power-efficiency of transformers, while hackers like me struggle to access them in applications. Boltzmann machines aren't on anyone's radar. And yet none of the developers of the transformer have won a Nobel prize or even a Turing award. The reason is simple&mdash;these awards are given by academics to academics, and commercial developers aren't included.